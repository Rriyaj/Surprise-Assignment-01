{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ede7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter string:Hello Hello how are you you\n",
      "{'Hello': 2, 'how': 1, 'are': 1, 'you': 2}\n"
     ]
    }
   ],
   "source": [
    "#Solution 01:\n",
    "string = input('Enter string:')\n",
    "j=string.split()\n",
    "d={}\n",
    "for i in j:\n",
    "    if i not in d.keys():\n",
    "        d[i]=0\n",
    "    d[i] = d[i]+1\n",
    "print(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c261909f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter String:HANNAH\n",
      "Palindrome String\n"
     ]
    }
   ],
   "source": [
    "#Solution 2\n",
    "a = input(\"Enter String:\")\n",
    "b=a[-1::-1]\n",
    "if(a==b):\n",
    "    print(\"Palindrome String\")\n",
    "else:\n",
    "    print(\"Not Palindrome string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cfb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDERFITTING - Underfitting is a scenario in data science where a data model is unable to capture the \n",
    "#relationship between the input and output variables accurately, generating a high error rate on both the \n",
    "#training set and unseen data. It occurs when a model is too simple, which can be a result of a model needing\n",
    "#more training time, more input features, or less regularization. Like overfitting, when a model is underfitted,\n",
    "#it cannot establish the dominant trend within the data, resulting in training errors and poor performance of the model.\n",
    "#If a model cannot generalize well to new data, then it cannot be leveraged for classification or prediction tasks. Generalization of a model to new data is ultimately what allows us to use machine learning algorithms\n",
    "#every day to make predictions and classify data.\n",
    "\n",
    "\n",
    "\n",
    "#OVERFITTING- Overfitting occurs when our machine learning model tries to cover all the data points or more than the required\n",
    "#data points present in the given dataset. Because of this, the model starts caching noise and inaccurate values \n",
    "#present in the dataset, and all these factors reduce the efficiency and accuracy of the model. \n",
    "#The overfitted model has low bias and high variance.\n",
    "# The chances of occurrence of overfitting increase as much we provide training\n",
    "#to our model. It means the more we train our model, the more chances of \n",
    "#occurring the overfitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980199b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accoring to the problem acquire the solution or acquire the dataset\n",
    "#Import the dataset into the python and then import all the necessary libraries.\n",
    "#Handle the dataset or edit the dataset\n",
    "#Categorising the dataset\n",
    "#Scale the dataset according to a specific range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  5 steps in a ML Project lifecycle\n",
    "\"\"\"\n",
    "1. Data Collection\n",
    "Preparing customer data for meaningful ML projects can be a daunting task due to\n",
    "#the sheer number of disparate data sources and data silos that exist in organizations.\n",
    "#To build an accurate model it’s critical to select data that is likely to be predictive of\n",
    "#the target—the outcome which you hope the model will predict based on other input data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. Data Normalization\n",
    "The next step in the ML process is where analysts and data scientists typically spend most of their time on analysis projects: cleaning and normalizing dirty data.\n",
    "This oftentimes requires data scientists to make decisions on data they may not understand, like what to do with missing data,\n",
    "incomplete data, and outliers.\n",
    "\n",
    "This data may not be easily correlated to the proper unit of analysis: the customer.\n",
    "In order to predict if a single customer will churn, for example, siloed data from disparate sources can’t be relied on.\n",
    "A data scientist will prepare and aggregate all of the data from those sources into a format that ML models can interpret. \n",
    "This can end up being a lengthy process and may require a lot of work before any ML can even occur.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3. Data Modeling\n",
    "The next phase of an ML project is to model the data that will be used for prediction. Part of modeling data for a prediction\n",
    "about customers is to combine disparate data sets to paint a proper picture of a single customer. \n",
    "This includes blending and aggregating silos of data like web, mobile app, and offline data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. Model Training and Feature Engineering\n",
    "After a brand has deployed collection and enrichment of meaningful input data, it’s time to put the predictive power\n",
    "of that data to the test. To do so, data scientists take a representative sample of the population \n",
    "(i.e. all customers, anonymous visitors, or known prospects) and set aside a portion for training models.\n",
    "The remainder is used to validate the models after training is complete.\n",
    "\n",
    "A key component of this phase is to iterate rapidly, continuously testing new data points that can be derived \n",
    "from the data source. This process is called feature engineering.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf98f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. Deploying Models to Production\n",
    "All work to this point culminates in the final step of deploying a model to production\n",
    "where the ability to predict outcomes in the real world is tested. By this point, models should meet some \n",
    "threshold of accuracy that warrants deploying them to production. For this reason, it’s important to interpret \n",
    "model performance with stakeholders to agree on what level of risk is acceptable for inaccuracy. Some customer\n",
    "behaviors may not be sufficiently predictable,\n",
    "and thus a model may never achieve accuracy to justify deploying to production.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84200db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e46ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989f037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
